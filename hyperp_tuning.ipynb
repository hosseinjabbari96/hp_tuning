{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBRfkLcQUGB6MLkYJn9+cu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qbZRpGYjBVTe"},"outputs":[],"source":["!pip install ucimlrepo\n","!pip install pyMetaheuristic\n","!pip install torchmetrics"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from torchmetrics import Accuracy\n","\n","from ucimlrepo import fetch_ucirepo\n","from sklearn.model_selection import train_test_split\n","from scipy import optimize\n","import numpy as np\n","import pandas as pd\n","import math\n","import random"],"metadata":{"id":"QtFNly0zBZpO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Feature Selection"],"metadata":{"id":"wTDFI1ApDiMe"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"VcHjnQ0TDeDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fetch dataset\n","isolet = fetch_ucirepo(id=54)\n","\n","# data (as pandas dataframes)\n","X = isolet.data.features\n","y = isolet.data.targets\n","\n","y -=1"],"metadata":{"id":"5H3U9uRzBZhN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AverageMeter():\n","    \"\"\"Computes and stores the average and current loss value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"iuuxEnXIBZd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None):\n","  model.train()\n","  loss_train = AverageMeter()\n","  acc_train = Accuracy(task='multiclass', num_classes=26).to(device)\n","  #with tqdm(train_loader, unit='batch') as tepoch:\n","  for inputs, targets in train_loader:\n","      #if epoch is not None:\n","      # tepoch.set_description(f'Epoch {epoch}')\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      outputs = model(inputs)\n","      loss = loss_fn(outputs, targets)\n","\n","      loss.backward()\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","      loss_train.update(loss.item())\n","      acc_train(outputs, targets.int())\n","\n","      #tepoch.set_postfix(loss=loss_train.avg,\n","      #                   accuracy=100.*acc_train.compute().item())\n","  return model, loss_train.avg, acc_train.compute().item()"],"metadata":{"id":"SOVGgk5nBZax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, valid_loader, loss_fn):\n","  model.eval()\n","  with torch.no_grad():\n","    loss_valid = AverageMeter()\n","    acc_valid = Accuracy(task='multiclass', num_classes=26).to(device)\n","    for i, (inputs, targets) in enumerate(valid_loader):\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      outputs = model(inputs)\n","      loss = loss_fn(outputs, targets)\n","\n","      loss_valid.update(loss.item())\n","      acc_valid(outputs, targets.int())\n","\n","  return loss_valid.avg, acc_valid.compute()"],"metadata":{"id":"p2VkKP2GBZYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RecurrentModel(nn.Module):\n","  def __init__(self, model, input_size, hidden_size, num_layers, bidirectional):\n","    super().__init__()\n","    self.rnn = model(input_size = input_size,\n","                      hidden_size = hidden_size,\n","                      num_layers = num_layers,\n","                      bidirectional = bidirectional,\n","                      batch_first = True)\n","    self.fc = nn.LazyLinear(26)\n","\n","  def forward(self, x):\n","    outputs, _ = self.rnn(x)\n","    #print(outputs.shape)\n","    y = self.fc(outputs) # out: many[:, -1, :]\n","    #y = y.mean(dim=1)\n","    return y"],"metadata":{"id":"pjThYgUYBZVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def si_opt(method = 'aro', obj = lambda x : x**2 , lb =[- np.inf] , ub = [np.inf], dim = 1, npop = 50, max_it = 100):\n","    '''\n","    4 Swarm INtelligence Optimizer: aro, woa, gwo, pso\n","    '''\n","    if method == 'aro' :\n","        from torch import randperm\n","\n","        def space_bound(X, Up, Low):\n","            dim = len(X)\n","            S = (X > Up) + (X < Low)\n","            res = (np.random.rand(dim) * (np.array(Up) - np.array(Low)) + np.array(Low)) * S + X * (~S)\n","            return res\n","\n","\n","        if len(lb) == 1:\n","            lb = lb * dim\n","            ub = ub * dim\n","\n","        pop_pos = np.zeros((npop, dim))\n","        for i in range(dim):\n","            pop_pos[:, i] = np.random.rand(npop) * (ub[i] - lb[i]) + lb[i]\n","        pop_fit = np.zeros(npop)\n","        for i in range(npop):\n","            pop_fit[i] = obj(pop_pos[i, :])\n","\n","        best_f = float('inf')\n","        best_x = []\n","        for i in range(npop):\n","            if pop_fit[i] <= best_f:\n","                best_f = pop_fit[i]\n","                best_x = pop_pos[i, :]\n","\n","        for it in range(max_it):\n","            direct1 = np.zeros((npop, dim))\n","            direct2 = np.zeros((npop, dim))\n","            theta = 2 * (1 - (it+1) / max_it)\n","            for i in range(npop):\n","                L = (np.e - np.exp((((it+1) - 1) / max_it) ** 2)) * (np.sin(2 * np.pi * np.random.rand())) # Eq.(3)\n","                rd = np.floor(np.random.rand() * (dim))\n","                rand_dim = randperm(dim)\n","                direct1[i, rand_dim[:int(rd)]] = 1\n","                c = direct1[i,:]  #Eq.(4)\n","                R = L * c # Eq.(2)\n","                A = 2 * np.log(1 / np.random.rand()) * theta #Eq.(15)\n","\n","                if A>1:\n","                  K=np.r_[0:i,i+1:npop]\n","                  RandInd=(K[np.random.randint(0,npop-1)])\n","                  newPopPos = pop_pos[RandInd, :] + R * (pop_pos[i, :] - pop_pos[RandInd, :])+round(0.5 * (0.05 +np.random.rand())) * np.random.randn()\n","                  # Eq.(1)\n","                else:\n","                    ttt = int(np.floor(np.random.rand() * dim))\n","                    direct2[i, ttt] = 1\n","                    gr = direct2[i,:] #Eq.(12)\n","                    H = ((max_it - (it+1) + 1) / max_it) * np.random.randn() # % Eq.(8)\n","                    b = pop_pos[i,:] + H * gr * pop_pos[i,:] # % Eq.(13)\n","                    newPopPos = pop_pos[i,:]+ R* (np.random.rand() * b - pop_pos[i,:]) #Eq.(11)\n","\n","                newPopPos = space_bound(newPopPos, ub, lb)\n","                newPopFit = obj(newPopPos)\n","\n","                if newPopFit < pop_fit[i]:\n","                    pop_fit[i] = newPopFit\n","                    pop_pos[i, :] = newPopPos\n","\n","                if pop_fit[i] < best_f:\n","                    best_f = pop_fit[i]\n","                    best_x = pop_pos[i, :]\n","\n","            print(f'The Minimum value at iteration {it} is equal to: {best_f}')\n","\n","        print()\n","\n","        return best_x, best_f\n","\n","    elif method == \"woa\" :\n","        import random\n","        import copy\n","        import sys\n","        import math\n","\n","        class whale:\n","            def __init__(self, fitness, dim, minx, maxx, seed):\n","                self.rnd = random.Random(seed)\n","                self.position = [0.0 for i in range(dim)]\n","\n","                for i in range(dim):\n","                    self.position[i] = ((maxx - minx) * self.rnd.random() + minx)\n","\n","                self.fitness = fitness(self.position)\n","\n","\n","        def woa(fitness, max_iter, n, dim, minx, maxx):\n","            rnd = random.Random(0)\n","\n","            # create n random whales\n","            whalePopulation = [whale(fitness, dim, minx, maxx, i) for i in range(n)]\n","\n","            # compute the value of best_position and best_fitness in the whale Population\n","            Xbest = [0.0 for i in range(dim)]\n","            Fbest = sys.float_info.max\n","\n","            for i in range(n): # check each whale\n","                if whalePopulation[i].fitness < Fbest:\n","                    Fbest = whalePopulation[i].fitness\n","                    Xbest = copy.copy(whalePopulation[i].position)\n","\n","            # main loop of woa\n","            Iter = 0\n","            while Iter < max_iter:\n","                # linearly decreased from 2 to 0\n","                a = 2 * (1 - Iter / max_iter)\n","                a2 = -1+Iter*((-1)/max_iter)\n","\n","                for i in range(n):\n","                    A = 2 * a * rnd.random() - a\n","                    C = 2 * rnd.random()\n","                    b = 1\n","                    l = (a2-1)*rnd.random()+1;\n","                    p = rnd.random()\n","\n","                    D = [0.0 for i in range(dim)]\n","                    D1 = [0.0 for i in range(dim)]\n","                    Xnew = [0.0 for i in range(dim)]\n","                    Xrand = [0.0 for i in range(dim)]\n","\n","                    if p < 0.5:\n","                        if abs(A) > 1:\n","                            for j in range(dim):\n","                                D[j] = abs(C * Xbest[j] - whalePopulation[i].position[j])\n","                                Xnew[j] = Xbest[j] - A * D[j]\n","                        else:\n","                            p = random.randint(0, n - 1)\n","                            while (p == i):\n","                                p = random.randint(0, n - 1)\n","\n","                            Xrand = whalePopulation[p].position\n","\n","                            for j in range(dim):\n","                                D[j] = abs(C * Xrand[j] - whalePopulation[i].position[j])\n","                                Xnew[j] = Xrand[j] - A * D[j]\n","                    else:\n","                        for j in range(dim):\n","                            D1[j] = abs(Xbest[j] - whalePopulation[i].position[j])\n","                            Xnew[j] = D1[j] * math.exp(b * l) * math.cos(2 * math.pi * l) + Xbest[j]\n","\n","                    for j in range(dim):\n","                        whalePopulation[i].position[j] = Xnew[j]\n","\n","                for i in range(n):\n","                # if Xnew < minx OR Xnew > maxx\n","                # then clip it\n","                    for j in range(dim):\n","                        whalePopulation[i].position[j] = max(whalePopulation[i].position[j], minx)\n","                        whalePopulation[i].position[j] = min(whalePopulation[i].position[j], maxx)\n","\n","                    whalePopulation[i].fitness = fitness(whalePopulation[i].position)\n","\n","                    if (whalePopulation[i].fitness < Fbest):\n","                        Xbest = copy.copy(whalePopulation[i].position)\n","                        Fbest = whalePopulation[i].fitness\n","\n","\n","                print(f'Minimum Value at iteration {Iter} is equal to: {Fbest}')\n","                Iter += 1\n","                # end-while\n","\n","            # returning the best solution\n","            return Xbest, Fbest\n","\n","        best_x, best_f = woa(obj,max_it, npop, dim, lb[0], ub[0])\n","        return np.array(best_x) , best_f\n","\n","\n","    elif method == 'gwo' :\n","\n","        import random\n","        class solution:\n","            def __init__(self):\n","                self.best = 0\n","                self.bestIndividual = []\n","                self.lb = 0\n","                self.ub = 0\n","                self.dim = 0\n","                self.popnum = 0\n","                self.maxiers = 0\n","\n","        def gwo(objf, lb, ub, dim, SearchAgents_no, Max_iter):\n","\n","            # initialize alpha, beta, and delta_pos\n","            Alpha_pos = np.zeros(dim)\n","            Alpha_score = float(\"inf\")\n","\n","            Beta_pos = np.zeros(dim)\n","            Beta_score = float(\"inf\")\n","\n","            Delta_pos = np.zeros(dim)\n","            Delta_score = float(\"inf\")\n","\n","            if not isinstance(lb, list):\n","                lb = [lb] * dim\n","            if not isinstance(ub, list):\n","                ub = [ub] * dim\n","\n","            if len(lb) == 1:\n","                lb = lb * dim\n","            if len(ub) == 1:\n","                ub = ub * dim\n","\n","            # Initialize the positions of search agents\n","            Positions = np.zeros((SearchAgents_no, dim))\n","            for i in range(dim):\n","                Positions[:, i] = (\n","                    np.random.uniform(0, 1, SearchAgents_no) * (ub[i] - lb[i]) + lb[i]\n","                )\n","\n","            s = solution()\n","            # Main loop\n","            for l in range(0, Max_iter):\n","                a_pos = 0\n","                for i in range(0, SearchAgents_no):\n","\n","                    # Return back the search agents that go beyond the boundaries of the search space\n","                    for j in range(dim):\n","                        Positions[i, j] = np.clip(Positions[i, j], lb[j], ub[j])\n","\n","                    # Calculate objective function for each search agent\n","                    fitness = objf(Positions[i, :])\n","\n","                    # Update Alpha, Beta, and Delta\n","                    if fitness < Alpha_score:\n","                        a_pos = i\n","                        Delta_score = Beta_score  # Update delte\n","                        Delta_pos = Beta_pos.copy()\n","                        Beta_score = Alpha_score  # Update beta\n","                        Beta_pos = Alpha_pos.copy()\n","                        Alpha_score = fitness\n","                        # Update alpha\n","                        Alpha_pos = Positions[i, :].copy()\n","\n","                    if fitness > Alpha_score and fitness < Beta_score:\n","                        Delta_score = Beta_score  # Update delte\n","                        Delta_pos = Beta_pos.copy()\n","                        Beta_score = fitness  # Update beta\n","                        Beta_pos = Positions[i, :].copy()\n","\n","                    if fitness > Alpha_score and fitness > Beta_score and fitness < Delta_score:\n","                        Delta_score = fitness  # Update delta\n","                        Delta_pos = Positions[i, :].copy()\n","\n","                a = 2 - l * ((2) / Max_iter)\n","                # a decreases linearly fron 2 to 0\n","\n","                # Update the Position of search agents including omegas\n","                for i in range(0, SearchAgents_no):\n","                    for j in range(0, dim):\n","\n","                        r1 = random.random()  # r1 is a random number in [0,1]\n","                        r2 = random.random()  # r2 is a random number in [0,1]\n","\n","                        A1 = 2 * a * r1 - a\n","                        # Equation (3.3)\n","                        C1 = 2 * r2\n","                        # Equation (3.4)\n","\n","                        D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])\n","                        # Equation (3.5)-part 1\n","                        X1 = Alpha_pos[j] - A1 * D_alpha\n","                        # Equation (3.6)-part 1\n","\n","                        r1 = random.random()\n","                        r2 = random.random()\n","\n","                        A2 = 2 * a * r1 - a\n","                        # Equation (3.3)\n","                        C2 = 2 * r2\n","                        # Equation (3.4)\n","\n","                        D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])\n","                        # Equation (3.5)-part 2\n","                        X2 = Beta_pos[j] - A2 * D_beta\n","                        # Equation (3.6)-part 2\n","\n","                        r1 = random.random()\n","                        r2 = random.random()\n","\n","                        A3 = 2 * a * r1 - a\n","                        # Equation (3.3)\n","                        C3 = 2 * r2\n","                        # Equation (3.4)\n","\n","                        D_delta = abs(C3 * Delta_pos[j] - Positions[i, j])\n","                        # Equation (3.5)-part 3\n","                        X3 = Delta_pos[j] - A3 * D_delta\n","                        # Equation (3.5)-part 3\n","\n","                        Positions[i, j] = (X1 + X2 + X3) / 3  # Equation (3.7)\n","\n","                print([\"At iteration \" + str(l) + \" the best fitness is \" + str(Alpha_score)])\n","\n","            s.bestIndividual = Alpha_pos\n","            s.best = Alpha_score\n","            print()\n","            return s\n","\n","        solve = gwo(obj, lb, ub, dim, npop, max_it)\n","        return solve.bestIndividual , solve.best\n","\n","    elif method == 'pso' :\n","\n","        from pyMetaheuristic.algorithm import particle_swarm_optimization as pso\n","\n","        if len(lb) == 1:\n","            lb = lb * dim\n","        if len(ub) == 1:\n","            ub = ub * dim\n","\n","        parameters = {\n","        'swarm_size': npop,\n","        'min_values': lb,\n","        'max_values': ub,\n","        'iterations': max_it - 1,\n","        'decay': 0,\n","        'w': 0.9,\n","        'c1': 2,\n","        'c2': 2\n","        }\n","\n","        solve = pso(target_function = obj, **parameters)\n","        x_best = solve[:-1]\n","        f_best = solve[-1]\n","        return x_best, f_best\n","\n","    else:\n","      raise Exception(\"You should choose one of 4 suggested methods\")"],"metadata":{"id":"D18Ar6IYBZM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def binary_conversion(x, thresh = 0.5):\n","    for i in range(len(x)):\n","        if x[i] > thresh:\n","            x[i] = 1\n","        else:\n","            x[i] = 0\n","    return x\n","\n","def feature_selector(binary_vec):\n","    features = []\n","    for i in range(len(binary_vec)):\n","        if binary_vec[i] == 1:\n","            features.append(i)\n","    return features\n","\n","\n","def fs(v):\n","    ''' feature selector '''\n","    binary_vector = binary_conversion(v)\n","    x = X.iloc[:, feature_selector(binary_vector)]\n","\n","    x_train, x_valid, y_train, y_valid = train_test_split(x, y, train_size=0.8, random_state=24)\n","    x_train = torch.FloatTensor(x_train.values)\n","    y_train = torch.LongTensor(y_train['class'].values)\n","\n","    x_valid = torch.FloatTensor(x_valid.values)\n","    y_valid = torch.LongTensor(y_valid['class'].values)\n","\n","    mu = x_train.mean(dim=0)\n","    std = x_train.std(dim=0)\n","\n","    x_train = (x_train - mu) / std\n","    x_valid = (x_valid - mu) / std\n","\n","    train_dataset = TensorDataset(x_train, y_train)\n","    train_loader = DataLoader(train_dataset, 20, True)\n","\n","    valid_dataset = TensorDataset(x_valid, y_valid)\n","    valid_loader = DataLoader(valid_dataset, 40, False)\n","\n","\n","    num_feats = x.shape[1]\n","    model = RecurrentModel(nn.LSTM, num_feats, 100, 1, False)\n","\n","    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","    loss_fn = nn.CrossEntropyLoss()\n","    best_loss = torch.inf\n","    num_epochs = 5\n","\n","    for epoch in range(num_epochs):\n","  # Train\n","        model, loss_train, acc_train = train_one_epoch(model,\n","                                                 train_loader,\n","                                                 loss_fn,\n","                                                 optimizer,\n","                                                 epoch)\n","  # Validation\n","        loss_valid, acc_valid = evaluate(model,\n","                                     valid_loader,\n","                                     loss_fn)\n","\n","        if loss_train < best_loss:\n","            best_loss = loss_train\n","\n","    return 0.5 * best_loss + 0.5 * (num_feats / (617 - num_feats))"],"metadata":{"id":"lplbJCDIB-JU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sol = si_opt('aro', fs, [0], [1], 617, npop = 10, max_it = 30)\n","binary_v = sol[0]"],"metadata":{"id":"lxlbeJhyB-Gj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameter Tuning"],"metadata":{"id":"fhPUE6nmD9_C"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"tyHslndeB-BA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = X.iloc[:, feature_selector(binary_v)]"],"metadata":{"id":"YqUOWITAB-Dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, x_valid, y_train, y_valid = train_test_split(x, y, train_size=0.8, random_state=42)\n","\n","x_train = torch.FloatTensor(x_train.values)\n","y_train = torch.LongTensor(y_train['class'].values)\n","\n","x_valid = torch.FloatTensor(x_valid.values)\n","y_valid = torch.LongTensor(y_valid['class'].values)\n","\n","mu = x_train.mean(dim=0)\n","std = x_train.std(dim=0)\n","\n","x_train = (x_train - mu) / std\n","x_valid = (x_valid - mu) / std\n","\n","train_dataset = TensorDataset(x_train, y_train)\n","train_loader = DataLoader(train_dataset, 20, True)\n","\n","valid_dataset = TensorDataset(x_valid, y_valid)\n","valid_loader = DataLoader(valid_dataset, 20, True)"],"metadata":{"id":"DMnTmleBB9-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","\n","  def __init__(self, num_enc, d_model, nhead, nd_feed, dropout = 0.1, af = 'relu', num_cls = 26):\n","    super().__init__()\n","\n","    self.encoder = nn.TransformerEncoderLayer(d_model,\n","                                  nhead,\n","                                  nd_feed * d_model,\n","                                  dropout,\n","                                  af,\n","                                  batch_first=True,\n","                                  device = 'cuda')\n","\n","    self.model = nn.TransformerEncoder(self.encoder, num_enc)\n","\n","    # classifier\n","    self.fc = nn.LazyLinear(num_cls)\n","\n","    # input layer\n","    self.linear = nn.LazyLinear(d_model)\n","    self.bn = nn.LazyBatchNorm1d()\n","\n","  def forward(self, x):\n","    x = self.bn(self.linear(x)).relu()\n","    y = self.model(x)\n","    y = self.fc(y)\n","    return y"],"metadata":{"id":"cBtj-ZDiB97k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TransformerModel(1, 128, 8, 4, 0.1, 'relu').to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","lr = 1e-3\n","optimizer = optim.Adam(model.parameters(), lr = lr)\n","\n","best_valid_loss = torch.inf"],"metadata":{"id":"ltlNOAHsB94r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = []\n","for _ in range(10):\n","    model = TransformerModel(1, 128, 8, 4, 0.1, 'relu').to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    lr = 1e-3\n","    optimizer = optim.Adam(model.parameters(), lr = lr)\n","    best_valid_loss = torch.inf\n","    num_epochs = 10\n","    for epoch in range(num_epochs):\n","        # Train\n","        model, loss_train, acc_train = train_one_epoch(model,\n","                                          train_loader,\n","                                          loss_fn,\n","                                          optimizer,\n","                                          epoch)\n","\n","        # Validation\n","        loss_valid, acc_valid = evaluate(model,\n","                                      valid_loader,\n","                                      loss_fn)\n","\n","        if loss_valid < best_valid_loss:\n","            best_valid_loss = loss_valid\n","    print(f'Best Valid Loss at iteration {_} = {best_valid_loss:.4}')\n","    print()\n","    losses.append(best_valid_loss)"],"metadata":{"id":"ZfXIQb2HB916"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Average of best valid loss = {np.mean(losses)}')\n","print(f'Std of best valid loss = {np.std(losses)}')"],"metadata":{"id":"BQC7p9-MCz-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def hp_tuning(p):\n","    num_enc = int(6 * p[0]) + 1\n","    nhead = 2 ** (int(6 * p[1]) + 1)\n","    nd_feed = int(4 * p[2]) + 1\n","    dropout = p[3]\n","    af = 'relu' if p[4] >= 0.5 else 'gelu'\n","    lr = p[5] / 100\n","\n","    model = TransformerModel(num_enc, 128, nhead, nd_feed, dropout, af).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr = lr)\n","    best_loss = torch.inf\n","\n","    num_epochs = 10\n","\n","    for epoch in range(num_epochs):\n","        # Train\n","        model, loss_train, acc_train = train_one_epoch(model,\n","                                             train_loader,\n","                                             loss_fn,\n","                                             optimizer)\n","\n","        # Validation\n","        loss_valid, acc_valid = evaluate(model,\n","                                     valid_loader,\n","                                     loss_fn)\n","\n","        if loss_valid < best_loss:\n","            best_loss = loss_valid\n","\n","    return best_loss"],"metadata":{"id":"nC1heHFdCz6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = []\n","for _ in range(10):\n","    if _ == 0:\n","        print(f'{_ + 1}st Loop:')\n","    elif _ == 1:\n","        print(f'{_ + 1}nd Loop:')\n","    elif _ == 2:\n","        print(f'{_ + 1}rd Loop:')\n","    else:\n","        print(f'{_ + 1}th Loop:')\n","    ans = si_opt('aro', hp_tuning, [0], [1], 6, npop = 10, max_it = 20)\n","    err = ans[1]\n","    enc = int(6 * ans[0][0]) + 1\n","    h = 2 ** (int(6 * ans[0][1]) + 1)\n","    feed = (int(4 * ans[0][2]) + 1) * 128\n","    d = ans[0][3]\n","    f = 1 if ans[0][4] >= 0.5 else 0\n","    l = ans[0][-1] / 100\n","    history.append((enc, h, feed, d, f, l, err))"],"metadata":{"id":"KfhrNgxKCz1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Results for ARO:')\n","print()\n","print(f'Average of Validation Loss = {np.mean([res[-1] for res in history])}')\n","print(f'Std of Validation Loss = {np.std([res[-1] for res in history])}')\n","print()\n","print(f'Average of layers = {np.mean([res[0] for res in history])}')\n","print(f'Average of attention heads = {np.mean([res[1] for res in history])}')\n","print(f'Average of feed-forward dimension = {np.mean([res[2] for res in history])}')\n","print(f'Average of dropout = {np.mean([res[3] for res in history])}')\n","print(f'prefered activation function = {np.mean([res[4] for res in history])}')\n","print(f'Average of learning rate = {np.mean([res[5] for res in history])}')"],"metadata":{"id":"9i4lfao8CzwE"},"execution_count":null,"outputs":[]}]}